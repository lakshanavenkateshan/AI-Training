Polynomial Regression is used when the relationship between input x and output y is curved, not a straight line.

The general equation is:
y = b0 + b1*x + b2*x^2 + b3*x^3 + ... + bn*x^n

Even though the curve is non-linear, it is still called linear regression because the model is linear in terms of its coefficients (b0, b1, b2...).

Polynomial Regression is useful when data shows patterns like:

ğŸ”¹U-shape
ğŸ”¹hill shape
ğŸ”¹waves
ğŸ”¹curves instead of straight trends

The method works by adding extra feature columns such as:
x^2, x^3, x^4, ...

This helps the model capture bending and curving patterns.

Model behaviour:

ğŸ”¹If degree is too low â†’ model is too simple â†’ underfitting
ğŸ”¹If degree is too high â†’ model memorizes noise â†’ overfitting

Where it is commonly used:

ğŸ”¹Price prediction
ğŸ”¹Growth curves
ğŸ”¹Physics experiments
ğŸ”¹Performance curves
ğŸ”¹Weather/temperature patterns

Visualization:

ğŸ”¹Linear regression â†’ straight line
ğŸ”¹Polynomial regression â†’ smooth bending curve
The model uses the least squares method to find the best coefficients.
Each coefficient tells how much that power of x (x, x^2, x^3...) affects the output y.
